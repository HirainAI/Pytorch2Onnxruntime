ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda/bin/nvcc

cflags = -pthread -B /root/anaconda3/envs/pytorch/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/TH -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/workspace/onnxruntime_inference_test/custom_test -I/root/anaconda3/envs/pytorch/include/python3.6m -c
post_cflags = -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fps -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14
cuda_cflags = -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/TH -I/root/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/root/workspace/onnxruntime_inference_test/custom_test -I/root/anaconda3/envs/pytorch/include/python3.6m -c
cuda_post_cflags = -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fps -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14
ldflags = 

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  command = $nvcc $cuda_cflags -c $in -o $out $cuda_post_cflags



build /root/workspace/onnxruntime_inference_test/custom_test/build/temp.linux-x86_64-3.6/sampling.o: compile /root/workspace/onnxruntime_inference_test/custom_test/sampling.cpp
build /root/workspace/onnxruntime_inference_test/custom_test/build/temp.linux-x86_64-3.6/sampling_gpu.o: cuda_compile /root/workspace/onnxruntime_inference_test/custom_test/sampling_gpu.cu





